{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  [1, 8, 1, 16, 1, 7, 14, 6, 5, 2, 1, 1, 1, 41]\n",
      "input_dim:  105\n",
      "\n",
      "output_dim:  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init global infos\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "inputs = (\n",
    "    (\"age\", (\"continuous\",)), \n",
    "    (\"workclass\", (\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \"State-gov\", \"Without-pay\", \"Never-worked\")), \n",
    "    (\"fnlwgt\", (\"continuous\",)), \n",
    "    (\"education\", (\"Bachelors\", \"Some-college\", \"11th\", \"HS-grad\", \"Prof-school\", \"Assoc-acdm\", \"Assoc-voc\", \"9th\", \"7th-8th\", \"12th\", \"Masters\", \"1st-4th\", \"10th\", \"Doctorate\", \"5th-6th\", \"Preschool\")), \n",
    "    (\"education-num\", (\"continuous\",)), \n",
    "    (\"marital-status\", (\"Married-civ-spouse\", \"Divorced\", \"Never-married\", \"Separated\", \"Widowed\", \"Married-spouse-absent\", \"Married-AF-spouse\")), \n",
    "    (\"occupation\", (\"Tech-support\", \"Craft-repair\", \"Other-service\", \"Sales\", \"Exec-managerial\", \"Prof-specialty\", \"Handlers-cleaners\", \"Machine-op-inspct\", \"Adm-clerical\", \"Farming-fishing\", \"Transport-moving\", \"Priv-house-serv\", \"Protective-serv\", \"Armed-Forces\")), \n",
    "    (\"relationship\", (\"Wife\", \"Own-child\", \"Husband\", \"Not-in-family\", \"Other-relative\", \"Unmarried\")), \n",
    "    (\"race\", (\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\")), \n",
    "    (\"sex\", (\"Female\", \"Male\")), \n",
    "    (\"capital-gain\", (\"continuous\",)), \n",
    "    (\"capital-loss\", (\"continuous\",)), \n",
    "    (\"hours-per-week\", (\"continuous\",)), \n",
    "    (\"native-country\", (\"United-States\", \"Cambodia\", \"England\", \"Puerto-Rico\", \"Canada\", \"Germany\", \"Outlying-US(Guam-USVI-etc)\", \"India\", \"Japan\", \"Greece\", \"South\", \"China\", \"Cuba\", \"Iran\", \"Honduras\", \"Philippines\", \"Italy\", \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\", \"Portugal\", \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\", \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\", \"Guatemala\", \"Nicaragua\", \"Scotland\", \"Thailand\", \"Yugoslavia\", \"El-Salvador\", \"Trinadad&Tobago\", \"Peru\", \"Hong\", \"Holand-Netherlands\"))\n",
    ")\n",
    "\n",
    "input_shape = []\n",
    "for i in inputs:\n",
    "    count = len(i[1 ])\n",
    "    input_shape.append(count)\n",
    "input_dim = sum(input_shape)\n",
    "print(\"input_shape: \", input_shape)\n",
    "print(\"input_dim: \", input_dim)\n",
    "print()\n",
    "\n",
    "\n",
    "outputs = (0, 1)  # (\">50K\", \"<=50K\")\n",
    "output_dim = 2  # len(outputs)\n",
    "print(\"output_dim: \", output_dim)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load and prepare data\n",
    "\n",
    "def isFloat(string):\n",
    "    # credits: http://stackoverflow.com/questions/2356925/how-to-check-whether-string-might-be-type-cast-to-float-in-python\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def find_means_for_continuous_types(X):\n",
    "    means = []\n",
    "    for col in range(len(X[0])):\n",
    "        summ = 0\n",
    "        count = 0.000000000000000000001\n",
    "        for value in X[:, col]:\n",
    "            if isFloat(value): \n",
    "                summ += float(value)\n",
    "                count +=1\n",
    "        means.append(summ/count)\n",
    "    return means\n",
    "\n",
    "def prepare_data(raw_data, means):\n",
    "    \n",
    "    X = raw_data[:, :-1]\n",
    "    y = raw_data[:, -1:]\n",
    "    \n",
    "    # X:\n",
    "    def flatten_persons_inputs_for_model(person_inputs):\n",
    "        global inputs\n",
    "        global input_shape\n",
    "        global input_dim\n",
    "        global means\n",
    "        float_inputs = []\n",
    "\n",
    "        for i in range(len(input_shape)):\n",
    "            features_of_this_type = input_shape[i]\n",
    "            is_feature_continuous = features_of_this_type == 1\n",
    "\n",
    "            if is_feature_continuous:\n",
    "                mean = means[i]\n",
    "                if isFloat(person_inputs[i]):\n",
    "                    scale_factor = 1/(2*mean)  # we prefer inputs mainly scaled from -1 to 1. \n",
    "                    float_inputs.append(float(person_inputs[i])*scale_factor)\n",
    "                else:\n",
    "                    float_inputs.append(mean)\n",
    "            else:\n",
    "                for j in range(features_of_this_type):\n",
    "                    feature_name = inputs[i][1][j]\n",
    "\n",
    "                    if feature_name == person_inputs[i]:\n",
    "                        float_inputs.append(1.)\n",
    "                    else:\n",
    "                        float_inputs.append(-1./features_of_this_type)\n",
    "        return float_inputs\n",
    "    \n",
    "    new_X = []\n",
    "    for person in range(len(X)):\n",
    "        formatted_X = flatten_persons_inputs_for_model(X[person])\n",
    "        new_X.append(formatted_X)\n",
    "    new_X = np.array(new_X)\n",
    "    \n",
    "    # y:\n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == \">50k\":\n",
    "            new_y.append((1, 0))\n",
    "        else:  # y[i] == \"<=50k\":\n",
    "            new_y.append((0, 1))\n",
    "    new_y = np.array(new_y)\n",
    "    \n",
    "    return (new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data count:  32561\n",
      "test data count:  16281\n",
      "mean values for data types (if continuous):  [38.64358543876172, 0.0, 189664.13459727284, 0.0, 10.078088530363212, 0.0, 0.0, 0.0, 0.0, 0.0, 1079.0676262233324, 87.50231358257237, 40.422382375824085, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Building training and test data\n",
    "\n",
    "training_data = np.genfromtxt('data/adult.data.txt', delimiter=', ', dtype=str, autostrip=True)\n",
    "print(\"training data count: \", len(training_data))\n",
    "test_data = np.genfromtxt('data/adult.test.txt', delimiter=', ', dtype=str, autostrip=True)\n",
    "print(\"test data count: \", len(test_data))\n",
    "\n",
    "means = find_means_for_continuous_types(np.concatenate((training_data, test_data), 0))\n",
    "print(\"mean values for data types (if continuous): \", means)\n",
    "\n",
    "X_train, y_train = prepare_data(training_data, means)\n",
    "X_test, y_test = prepare_data(test_data, means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explanation on data format\n",
    "\n",
    "print(\"Training data format example: \")\n",
    "print(X_train[4])  # 4 is a random person, from cuba. \n",
    "print()\n",
    "\n",
    "print(\"In fact, we just crushed the data in such a way that it will optimise the neural network (model). \\n\\\n",
    "It is crushed according to the `input_shape` variable: \\n\\\n",
    "    say, if there are 41 native countries in the dataset, there will be 41 input dimensions for the \\n\\\n",
    "    neural network with a value of 1/41 for every 41 input node for a given person, except that the \\n\\\n",
    "    node representing the real country of the person will have a value of 1.\")\n",
    "\n",
    "for i in X_train:\n",
    "    if len(i) != input_dim:\n",
    "        raise Exception(\n",
    "            \"Every person should have 105 data fields now. {} here.\".format(len(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(output_dim=output_dim, init='uniform', activation='sigmoid', input_dim=input_dim))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training_datas, dimension):  (32561, 105)\n",
      "Train on 29304 samples, validate on 3257 samples\n",
      "Epoch 0\n",
      "29304/29304 [==============================] - 0s - loss: 0.2531 - acc: 0.9940 - val_loss: 0.1222 - val_acc: 1.0000\n",
      "Epoch 1\n",
      "29304/29304 [==============================] - 0s - loss: 0.0906 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 1.0000\n",
      "Epoch 2\n",
      "29304/29304 [==============================] - 0s - loss: 0.0571 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 3\n",
      "29304/29304 [==============================] - 0s - loss: 0.0411 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 4\n",
      "29304/29304 [==============================] - 0s - loss: 0.0316 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
      "Epoch 5\n",
      "29304/29304 [==============================] - 0s - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 6\n",
      "29304/29304 [==============================] - 0s - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 7\n",
      "29304/29304 [==============================] - 0s - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 8\n",
      "29304/29304 [==============================] - 0s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 9\n",
      "29304/29304 [==============================] - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 10\n",
      "29304/29304 [==============================] - 0s - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 11\n",
      "29304/29304 [==============================] - 0s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 12\n",
      "29304/29304 [==============================] - 0s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 13\n",
      "29304/29304 [==============================] - 0s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 14\n",
      "29304/29304 [==============================] - 0s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 15\n",
      "29304/29304 [==============================] - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 16\n",
      "29304/29304 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 17\n",
      "29304/29304 [==============================] - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 18\n",
      "29304/29304 [==============================] - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 19\n",
      "29304/29304 [==============================] - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 20\n",
      "29304/29304 [==============================] - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 21\n",
      "29304/29304 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 22\n",
      "29304/29304 [==============================] - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 23\n",
      "29304/29304 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 24\n",
      "29304/29304 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 25\n",
      "29304/29304 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 26\n",
      "29304/29304 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 27\n",
      "29304/29304 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 28\n",
      "29304/29304 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 29\n",
      "29304/29304 [==============================] - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 30\n",
      "29304/29304 [==============================] - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 31\n",
      "29304/29304 [==============================] - 0s - loss: 0.0009 - acc: 1.0000 - val_loss: 0.0009 - val_acc: 1.0000\n",
      "Epoch 32\n",
      "29304/29304 [==============================] - 0s - loss: 0.0008 - acc: 1.0000 - val_loss: 0.0008 - val_acc: 1.0000\n",
      "Epoch 33\n",
      "29304/29304 [==============================] - 0s - loss: 0.0007 - acc: 1.0000 - val_loss: 0.0007 - val_acc: 1.0000\n",
      "Epoch 34\n",
      "29304/29304 [==============================] - 0s - loss: 0.0007 - acc: 1.0000 - val_loss: 0.0006 - val_acc: 1.0000\n",
      "Epoch 35\n",
      "29304/29304 [==============================] - 0s - loss: 0.0006 - acc: 1.0000 - val_loss: 0.0006 - val_acc: 1.0000\n",
      "Epoch 36\n",
      "29304/29304 [==============================] - 0s - loss: 0.0005 - acc: 1.0000 - val_loss: 0.0005 - val_acc: 1.0000\n",
      "Epoch 37\n",
      "29304/29304 [==============================] - 0s - loss: 0.0005 - acc: 1.0000 - val_loss: 0.0005 - val_acc: 1.0000\n",
      "Epoch 38\n",
      "29304/29304 [==============================] - 0s - loss: 0.0004 - acc: 1.0000 - val_loss: 0.0004 - val_acc: 1.0000\n",
      "Epoch 39\n",
      "29304/29304 [==============================] - 0s - loss: 0.0004 - acc: 1.0000 - val_loss: 0.0004 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca1b382d30>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "print(\"(training_datas, dimension): \", X_train.shape)\n",
    "# model.fit(new_X_train, y_train, nb_epoch=3, batch_size=16, show_accuracy=True, verbose=2)\n",
    "model.fit(X_train, y_train, nb_epoch=40, batch_size=128, validation_split=0.1, show_accuracy=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16281/16281 [==============================] - 0s     \n",
      "\n",
      "Keras evaluation result: 2.39971032984\n",
      "Percentage right: 76.3773723973 % on 16281 test entries on which we did not trained the neural network.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training\n",
    "\n",
    "score = model.evaluate(X_test, y_test, batch_size=16, verbose=1, show_accuracy=True)\n",
    "print()\n",
    "print(\"Keras evaluation result:\", score[0])\n",
    "print(\"Percentage right:\", score[1]*100, \"%\", \"on {} test entries \\\n",
    "on which we did not trained the neural network.\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
