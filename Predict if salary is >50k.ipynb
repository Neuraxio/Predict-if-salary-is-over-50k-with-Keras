{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  [1, 8, 1, 16, 1, 7, 14, 6, 5, 2, 1, 1, 1, 41]\n",
      "input_dim:  105\n",
      "\n",
      "output_dim:  2\n",
      "\n",
      "training data count:  48842\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "inputs = (\n",
    "    (\"age\", (\"continuous\",)), \n",
    "    (\"workclass\", (\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \"State-gov\", \"Without-pay\", \"Never-worked\")), \n",
    "    (\"fnlwgt\", (\"continuous\",)), \n",
    "    (\"education\", (\"Bachelors\", \"Some-college\", \"11th\", \"HS-grad\", \"Prof-school\", \"Assoc-acdm\", \"Assoc-voc\", \"9th\", \"7th-8th\", \"12th\", \"Masters\", \"1st-4th\", \"10th\", \"Doctorate\", \"5th-6th\", \"Preschool\")), \n",
    "    (\"education-num\", (\"continuous\",)), \n",
    "    (\"marital-status\", (\"Married-civ-spouse\", \"Divorced\", \"Never-married\", \"Separated\", \"Widowed\", \"Married-spouse-absent\", \"Married-AF-spouse\")), \n",
    "    (\"occupation\", (\"Tech-support\", \"Craft-repair\", \"Other-service\", \"Sales\", \"Exec-managerial\", \"Prof-specialty\", \"Handlers-cleaners\", \"Machine-op-inspct\", \"Adm-clerical\", \"Farming-fishing\", \"Transport-moving\", \"Priv-house-serv\", \"Protective-serv\", \"Armed-Forces\")), \n",
    "    (\"relationship\", (\"Wife\", \"Own-child\", \"Husband\", \"Not-in-family\", \"Other-relative\", \"Unmarried\")), \n",
    "    (\"race\", (\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\")), \n",
    "    (\"sex\", (\"Female\", \"Male\")), \n",
    "    (\"capital-gain\", (\"continuous\",)), \n",
    "    (\"capital-loss\", (\"continuous\",)), \n",
    "    (\"hours-per-week\", (\"continuous\",)), \n",
    "    (\"native-country\", (\"United-States\", \"Cambodia\", \"England\", \"Puerto-Rico\", \"Canada\", \"Germany\", \"Outlying-US(Guam-USVI-etc)\", \"India\", \"Japan\", \"Greece\", \"South\", \"China\", \"Cuba\", \"Iran\", \"Honduras\", \"Philippines\", \"Italy\", \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\", \"Portugal\", \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\", \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\", \"Guatemala\", \"Nicaragua\", \"Scotland\", \"Thailand\", \"Yugoslavia\", \"El-Salvador\", \"Trinadad&Tobago\", \"Peru\", \"Hong\", \"Holand-Netherlands\"))\n",
    ")\n",
    "\n",
    "input_shape = []\n",
    "for i in inputs:\n",
    "    count = len(i[1 ])\n",
    "    input_shape.append(count)\n",
    "input_dim = sum(input_shape)\n",
    "print(\"input_shape: \", input_shape)\n",
    "print(\"input_dim: \", input_dim)\n",
    "print()\n",
    "\n",
    "\n",
    "outputs = (\">50K\", \"<=50K\")\n",
    "\n",
    "output_dim = len(outputs)\n",
    "print(\"output_dim: \", output_dim)\n",
    "print()\n",
    "\n",
    "\n",
    "# We combined train and test data in a file to split them using\n",
    "# Keras functionalities at training time later in this script. \n",
    "all_data = np.genfromtxt('data/adult.all.txt', delimiter=', ', dtype=str, autostrip=True)\n",
    "print(\"training data count: \", len(all_data))\n",
    "\n",
    "X_train = all_data[:, :-1]\n",
    "y_train = all_data[:, -1:]\n",
    "# print(set(y_train.flatten()))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(output_dim=output_dim, init='uniform', input_dim=input_dim))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean values for data types (if continuous):  [38.64358543876172, 0.0, 189664.13459727284, 0.0, 10.078088530363212, 0.0, 0.0, 0.0, 0.0, 0.0, 1079.0676262233324, 87.50231358257237, 40.422382375824085, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def isFloat(string):\n",
    "    # http://stackoverflow.com/questions/2356925/how-to-check-whether-string-might-be-type-cast-to-float-in-python\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def find_means_for_continuous_types(X_train):\n",
    "    means = []\n",
    "    for col in range(len(X_train[0])):\n",
    "        summ = 0\n",
    "        count = 0.000000000000000000001\n",
    "        for value in X_train[:, col]:\n",
    "            if isFloat(value): \n",
    "                summ += float(value)\n",
    "                count +=1\n",
    "        means.append(summ/count)\n",
    "    return means\n",
    "\n",
    "means = find_means_for_continuous_types(X_train)\n",
    "print(\"mean values for data types (if continuous): \", means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def flatten_persons_inputs_for_model(person_inputs):\n",
    "    global inputs\n",
    "    global input_shape\n",
    "    global input_dim\n",
    "    global means\n",
    "    float_inputs = []\n",
    "    \n",
    "    for i in range(len(input_shape)):\n",
    "        features_of_this_type = input_shape[i]\n",
    "        is_feature_continuous = features_of_this_type == 1\n",
    "        \n",
    "        if is_feature_continuous:\n",
    "            mean = means[i]\n",
    "            if isFloat(person_inputs[i]):\n",
    "                scale_factor = 1/(2*mean)  # we prefer inputs mainly scaled from -1 to 1. \n",
    "                float_inputs.append(float(person_inputs[i])*scale_factor)\n",
    "            else:\n",
    "                float_inputs.append(mean)\n",
    "        \n",
    "        else:\n",
    "            for j in range(features_of_this_type):\n",
    "                feature_name = inputs[i][1][j]\n",
    "\n",
    "                if feature_name == person_inputs[i]:\n",
    "                    float_inputs.append(1.)\n",
    "                else:\n",
    "                    float_inputs.append(-1./features_of_this_type)\n",
    "    \n",
    "    # print(len(float_inputs), \"\\n\")\n",
    "    # print(float_inputs)\n",
    "    return float_inputs\n",
    "    \n",
    "new_X_train = []\n",
    "for person in range(len(X_train)):\n",
    "    formatted_X = flatten_persons_inputs_for_model(X_train[person])\n",
    "    new_X_train.append(formatted_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data format example: \n",
      "['28' 'Private' '338409' 'Bachelors' '13' 'Married-civ-spouse'\n",
      " 'Prof-specialty' 'Wife' 'Black' 'Female' '0' '0' '40' 'Cuba']\n",
      "\n",
      "New training data format example: \n",
      "[0.36228522382287026, 1.0, -0.125, -0.125, -0.125, -0.125, -0.125, -0.125, -0.125, 0.8921270242224961, 1.0, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, -0.0625, 0.6449635742350183, 1.0, -0.14285714285714285, -0.14285714285714285, -0.14285714285714285, -0.14285714285714285, -0.14285714285714285, -0.14285714285714285, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, 1.0, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, -0.07142857142857142, 1.0, -0.16666666666666666, -0.16666666666666666, -0.16666666666666666, -0.16666666666666666, -0.16666666666666666, -0.2, -0.2, -0.2, -0.2, 1.0, 1.0, -0.5, 0.0, 0.0, 0.4947753898830477, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, 1.0, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025, -0.024390243902439025]\n",
      "\n",
      "In fact, we just crushed the data in such a way that it will optimise the neural network (model). \n",
      "It is crushed according to the `input_shape` variable: \n",
      "    say, if there are 41 native countries in the dataset, there will be 41 input dimensions for the \n",
      "    neural network with a value of 1/41 for every 41 input node for a given person, except that the \n",
      "    node representing the real country of the person will have a value of 1.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training data format example: \")\n",
    "print(X_train[4])  # 4 is a random person, from cuba. \n",
    "print()\n",
    "\n",
    "print(\"New training data format example: \")\n",
    "print(new_X_train[4])\n",
    "print()\n",
    "\n",
    "print(\"In fact, we just crushed the data in such a way that it will optimise the neural network (model). \\n\\\n",
    "It is crushed according to the `input_shape` variable: \\n\\\n",
    "    say, if there are 41 native countries in the dataset, there will be 41 input dimensions for the \\n\\\n",
    "    neural network with a value of 1/41 for every 41 input node for a given person, except that the \\n\\\n",
    "    node representing the real country of the person will have a value of 1.\")\n",
    "\n",
    "for i in new_X_train:\n",
    "    if len(i) != input_dim:\n",
    "        raise Exception(\n",
    "            \"Every person should have 105 data fields now. {} here.\".format(len(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(new_X_train, y_train, nb_epoch=3, batch_size=16, validation_split=0.2, show_accuracy=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
